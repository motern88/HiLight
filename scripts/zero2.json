{
    "fp16?": "以Pytorch-like AMP方式开启混合精度训练",
    "fp16": {
        "enabled": true,
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power?": "控制loss scaler的初始缩放范围,可以增大这个值提高初始缩放范围，以解决混合精度loss溢出",
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },
    "communication_data_type?": "通信操作(All gather/scatter等)默认使用和模型训练相同的dtype，可能导致梯度的有损累积。强制通信启用高精度来回避损失",
    "communication_data_type": "fp32",
    "train_micro_batch_size_per_gpu": "auto",
    "train_batch_size": "auto",
    "gradient_accumulation_steps": "auto",
    "zero_optimization": {
        "stage": 2,
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": "auto"
    },
    "optimizer?": "显示定义默认值",
    "optimizer": {
       "type": "AdamW",
       "params": {
         "lr": "auto",
         "betas": "auto",
         "eps": "auto",
         "weight_decay": "auto"
       }
    }
}