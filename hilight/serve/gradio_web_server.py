import argparse
import datetime
import json
import os
import time

import gradio as gr
import requests

from hilight.conversation import (default_conversation, conv_templates,
                                        SeparatorStyle)
from hilight.constants import LOGDIR
from hilight.utils import (build_logger, server_error_msg,
    violates_moderation, moderation_msg)
import hashlib


logger = build_logger("gradio_web_server", "gradio_web_server.log")

headers = {"User-Agent": "HiLight Client"}

no_change_btn = gr.Button()
enable_btn = gr.Button(interactive=True)
disable_btn = gr.Button(interactive=False)

priority = {
    "vicuna-13b": "aaaaaaa",
    "koala-13b": "aaaaaab",
}

# æ ¹æ®å½“å‰æ—¥æœŸåˆ›å»ºä¸€ä¸ªæ–°çš„æ—¥å¿—æ–‡ä»¶åï¼Œç”¨äºå­˜å‚¨å¯¹è¯å†…å®¹ã€‚
def get_conv_log_filename():
    t = datetime.datetime.now()
    name = os.path.join(LOGDIR, f"{t.year}-{t.month:02d}-{t.day:02d}-conv.json")
    return name

# ä»æ§åˆ¶å™¨è·å–æ‰€æœ‰æ¨¡å‹çš„åˆ—è¡¨ï¼Œå¹¶æ ¹æ®ä¼˜å…ˆçº§æ’åºã€‚
def get_model_list():
    # å‘æ§åˆ¶å™¨å‘é€è¯·æ±‚ä»¥åˆ·æ–°å·¥ä½œèŠ‚ç‚¹ä¿¡æ¯
    ret = requests.post(args.controller_url + "/refresh_all_workers")
    # ç¡®ä¿è¯·æ±‚æˆåŠŸ
    assert ret.status_code == 200
    # ä»æ§åˆ¶å™¨è·å–æ¨¡å‹åˆ—è¡¨
    ret = requests.post(args.controller_url + "/list_models")
    models = ret.json()["models"]
    # æ ¹æ®ä¼˜å…ˆçº§å­—å…¸å¯¹æ¨¡å‹åˆ—è¡¨è¿›è¡Œæ’åº
    models.sort(key=lambda x: priority.get(x, x))
    logger.info(f"Models: {models}")
    return models


get_window_url_params = """
function() {
    const params = new URLSearchParams(window.location.search);
    url_params = Object.fromEntries(params);
    console.log(url_params);
    return url_params;
    }
"""

# åŠ è½½ä¸€ä¸ªç¤ºä¾‹å¯¹è¯ï¼Œæ ¹æ®URLå‚æ•°è®¾ç½®ä¸‹æ‹‰èœå•çš„é»˜è®¤å€¼ã€‚
def load_demo(url_params, request: gr.Request):
    logger.info(f"load_demo. ip: {request.client.host}. params: {url_params}")

    dropdown_update = gr.Dropdown(visible=True)
    # æ ¹æ®URLå‚æ•°ä¸­çš„"model"è®¾ç½®ä¸‹æ‹‰èœå•çš„é»˜è®¤å€¼
    if "model" in url_params:
        model = url_params["model"]
        if model in models:
            dropdown_update = gr.Dropdown(value=model, visible=True)
    # è¿”å›åˆå§‹å¯¹è¯çŠ¶æ€å’Œä¸‹æ‹‰èœå•
    state = default_conversation.copy()
    return state, dropdown_update

# åˆ·æ–°æ¨¡å‹åˆ—è¡¨å¹¶æ›´æ–°ä¸‹æ‹‰èœå•ã€‚
def load_demo_refresh_model_list(request: gr.Request):
    logger.info(f"load_demo. ip: {request.client.host}")
    models = get_model_list()
    state = default_conversation.copy()
    # æ›´æ–°ä¸‹æ‹‰èœå•çš„é€‰é¡¹å’Œé»˜è®¤å€¼
    dropdown_update = gr.Dropdown(
        choices=models,
        value=models[0] if len(models) > 0 else ""
    )
    # è¿”å›æ›´æ–°åçš„å¯¹è¯çŠ¶æ€å’Œä¸‹æ‹‰èœå•
    return state, dropdown_update

# è®°å½•ç”¨æˆ·å¯¹æœ€åä¸€æ¡å“åº”çš„æŠ•ç¥¨ï¼ˆç‚¹èµæˆ–ç‚¹è¸©ï¼‰ã€‚
def vote_last_response(state, vote_type, model_selector, request: gr.Request):
    # è®°å½•æŠ•ç¥¨ä¿¡æ¯åˆ°æ—¥å¿—æ–‡ä»¶
    with open(get_conv_log_filename(), "a") as fout:
        data = {
            "tstamp": round(time.time(), 4),
            "type": vote_type,
            "model": model_selector,
            "state": state.dict(),
            "ip": request.client.host,
        }
        fout.write(json.dumps(data) + "\n")

# åˆ†åˆ«å¤„ç†ç”¨æˆ·å¯¹æœ€åä¸€æ¡å“åº”çš„ç‚¹èµå’Œç‚¹è¸©æ“ä½œã€‚
def upvote_last_response(state, model_selector, request: gr.Request):
    logger.info(f"upvote. ip: {request.client.host}")
    # è®°å½•ç‚¹èµä¿¡æ¯
    vote_last_response(state, "upvote", model_selector, request)
    # è¿”å›æ›´æ–°åçš„å¯¹è¯çŠ¶æ€å’ŒæŒ‰é’®
    return ("",) + (disable_btn,) * 3
def downvote_last_response(state, model_selector, request: gr.Request):
    logger.info(f"downvote. ip: {request.client.host}")
    # è®°å½•ç‚¹è¸©ä¿¡æ¯
    vote_last_response(state, "downvote", model_selector, request)
    # è¿”å›æ›´æ–°åçš„å¯¹è¯çŠ¶æ€å’ŒæŒ‰é’®
    return ("",) + (disable_btn,) * 3

# è®°å½•ç”¨æˆ·å¯¹æœ€åä¸€æ¡å“åº”çš„ä¸¾æŠ¥æ“ä½œã€‚
def flag_last_response(state, model_selector, request: gr.Request):
    logger.info(f"flag. ip: {request.client.host}")
    vote_last_response(state, "flag", model_selector, request)
    return ("",) + (disable_btn,) * 3

# å¤„ç†ç”¨æˆ·è¯·æ±‚é‡æ–°ç”Ÿæˆå¯¹è¯å†…å®¹çš„æ“ä½œã€‚
def regenerate(state, video_process_mode, request: gr.Request):
    # è®°å½•æ—¥å¿—
    logger.info(f"regenerate. ip: {request.client.host}")
    # æ¸…é™¤æœ€åä¸€æ¡æ¶ˆæ¯
    state.messages[-1][-1] = None
    # è·å–ä¸Šä¸€æ¡äººç±»ç”¨æˆ·çš„æ¶ˆæ¯
    prev_human_msg = state.messages[-2]
    # å¦‚æœä¸Šä¸€æ¡æ¶ˆæ¯åŒ…å«å›¾ç‰‡ï¼Œæ›´æ–°å›¾ç‰‡å¤„ç†æ¨¡å¼
    if type(prev_human_msg[1]) in (tuple, list):
        prev_human_msg[1] = (*prev_human_msg[1][:2], video_process_mode)
    # é‡ç½®è·³è¿‡æ ‡å¿—
    state.skip_next = False
    # è¿”å›æ›´æ–°åçš„å¯¹è¯çŠ¶æ€å’ŒæŒ‰é’®
    return (state, state.to_gradio_chatbot(), "", None) + (disable_btn,) * 5

# å¤„ç†ç”¨æˆ·è¯·æ±‚æ¸…é™¤å¯¹è¯å†å²çš„æ“ä½œ
def clear_history(request: gr.Request):
    logger.info(f"clear_history. ip: {request.client.host}")
    # é‡ç½®å¯¹è¯çŠ¶æ€ä¸ºé»˜è®¤å€¼
    state = default_conversation.copy()
    # è¿”å›é‡ç½®åçš„å¯¹è¯çŠ¶æ€å’ŒæŒ‰é’®
    return (state, state.to_gradio_chatbot(), "", None) + (disable_btn,) * 5

# å¤„ç†ç”¨æˆ·è¾“å…¥æ–‡æœ¬å’Œè§†é¢‘çš„æ“ä½œ
def add_text(state, text, video, video_process_mode, request: gr.Request):
    logger.info(f"add_text. ip: {request.client.host}. len: {len(text)}")
    # æ£€æŸ¥è¾“å…¥æ˜¯å¦æœ‰æ•ˆ
    if len(text) <= 0 and video is None:
        state.skip_next = True
        return (state, state.to_gradio_chatbot(), "", None) + (no_change_btn,) * 5
    if args.moderate:
        flagged = violates_moderation(text)
        if flagged:
            state.skip_next = True
            return (state, state.to_gradio_chatbot(), moderation_msg, None) + (
                no_change_btn,) * 5

    text = text[:1536]  # Hard cut-off
    if video is not None:
        text = text[:1200]  # Hard cut-off for videos
        if '<video>' not in text:
            # text = '<video><video></video>' + text
            text = text + '\n<video>'
        text = (text, video, video_process_mode)
        if len(state.get_videos(return_pil=True)) > 0:
            state = default_conversation.copy()
    # å¦‚æœè¾“å…¥æœ‰æ•ˆï¼Œæ›´æ–°å¯¹è¯çŠ¶æ€
    state.append_message(state.roles[0], text)
    state.append_message(state.roles[1], None)
    # é‡ç½®è·³è¿‡æ ‡å¿—
    state.skip_next = False
    # è¿”å›æ›´æ–°åçš„å¯¹è¯çŠ¶æ€å’ŒæŒ‰é’®
    return (state, state.to_gradio_chatbot(), "", None) + (disable_btn,) * 5

# å¤„ç†ä¸æœºå™¨å­¦ä¹ æ¨¡å‹çš„äº¤äº’ï¼Œç”Ÿæˆå“åº”å¹¶æ›´æ–°ç•Œé¢ã€‚
def http_bot(state, model_selector, temperature, top_p, max_new_tokens, use_ocr, request: gr.Request):
    logger.info(f"http_bot. ip: {request.client.host}")
    # è·å–å½“å‰æ—¶é—´æˆ³
    start_tstamp = time.time()
    # è·å–æ¨¡å‹åç§°
    model_name = model_selector

    if state.skip_next:
        # ç”±äºè¾“å…¥æ— æ•ˆï¼Œè·³è¿‡ç”Ÿæˆè°ƒç”¨
        yield (state, state.to_gradio_chatbot()) + (no_change_btn,) * 5
        return

    if len(state.messages) == state.offset + 2:
        # ç¬¬ä¸€è½®å¯¹è¯
        # è®¾ç½®å¯¹è¯æ¨¡æ¿
        new_state = conv_templates["gemma"].copy()
        # å°†ä¸Šä¸€æ¡æ¶ˆæ¯æ·»åŠ åˆ°æ–°çŠ¶æ€ä¸­
        new_state.append_message(new_state.roles[0], state.messages[-2][1])
        new_state.append_message(new_state.roles[1], None)
        # å°†æ–°çŠ¶æ€è®¾ç½®ä¸ºå½“å‰çŠ¶æ€
        state = new_state

    # æŸ¥è¯¢å·¥ä½œèŠ‚ç‚¹åœ°å€
    controller_url = args.controller_url
    ret = requests.post(controller_url + "/get_worker_address",
            json={"model": model_name})
    worker_addr = ret.json()["address"]
    logger.info(f"model_name: {model_name}, worker_addr: {worker_addr}")

    # å¦‚æœæ²¡æœ‰å¯ç”¨çš„å·¥ä½œèŠ‚ç‚¹
    if worker_addr == "":
        state.messages[-1][-1] = server_error_msg
        yield (state, state.to_gradio_chatbot(), disable_btn, disable_btn, disable_btn, enable_btn, enable_btn)
        return

    # æ„é€ æç¤º
    prompt = state.get_prompt()
    # å¤„ç†å›¾åƒ
    all_videos = state.get_videos(return_pil=True)
    all_video_hash = [hashlib.md5(video.tobytes()).hexdigest() for video in all_videos]
    # ä¿å­˜è§†é¢‘åˆ°æ–‡ä»¶ç³»ç»Ÿ
    for video, hash in zip(all_videos, all_video_hash):
        t = datetime.datetime.now()
        filename = os.path.join(LOGDIR, "serve_videos", f"{t.year}-{t.month:02d}-{t.day:02d}", f"{hash}.jpg")
        if not os.path.isfile(filename):
            os.makedirs(os.path.dirname(filename), exist_ok=True)
            video.save(filename)


    # æ„é€ è¯·æ±‚è´Ÿè½½
    pload = {
        "model": model_name,
        "prompt": prompt,
        "temperature": float(temperature),
        "top_p": float(top_p),
        "max_new_tokens": min(int(max_new_tokens), 1536),
        "stop": state.sep if state.sep_style in [SeparatorStyle.SINGLE, SeparatorStyle.MPT] else state.sep2,
        "videos": f'List of {len(state.get_videos())} videos: {all_video_hash}',
        "use_ocr": bool(use_ocr == 'Yes'),
    }
    logger.info(f"==== request ====\n{pload}")

    pload['videos'] = state.get_videos()

    state.messages[-1][-1] = "â–Œ"
    yield (state, state.to_gradio_chatbot()) + (disable_btn,) * 5

    # å‘é€è¯·æ±‚
    try:
        # æµå¼è¾“å‡º
        response = requests.post(worker_addr + "/worker_generate_stream",
            headers=headers, json=pload, stream=True, timeout=30)
        for chunk in response.iter_lines(decode_unicode=False, delimiter=b"\0"):
            if chunk:
                data = json.loads(chunk.decode())
                if data["error_code"] == 0:
                    # å¦‚æœå“åº”ä¸­åŒ…å«æ–‡æœ¬
                    if 'video' not in data.keys():
                        output = data["text"][len(prompt):].strip()
                        state.messages[-1][-1] = output + "â–Œ"
                    else:
                        output = (data["text"][len(prompt):].strip(), data["video"])
                        state.messages[-1][-1] = output
                    yield (state, state.to_gradio_chatbot()) + (disable_btn,) * 5
                else:
                    # å¦‚æœå“åº”ä¸­åŒ…å«é”™è¯¯
                    output = data["text"] + f" (error_code: {data['error_code']})"
                    state.messages[-1][-1] = output
                    yield (state, state.to_gradio_chatbot()) + (disable_btn, disable_btn, disable_btn, enable_btn, enable_btn)
                    return
                time.sleep(0.03)
    except requests.exceptions.RequestException as e:
        # å¦‚æœè¯·æ±‚è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸
        state.messages[-1][-1] = server_error_msg
        yield (state, state.to_gradio_chatbot()) + (disable_btn, disable_btn, disable_btn, enable_btn, enable_btn)
        return

    if type(state.messages[-1][-1]) is not tuple:
        state.messages[-1][-1] = state.messages[-1][-1][:-1]
    yield (state, state.to_gradio_chatbot()) + (enable_btn,) * 5

    # è®°å½•å¯¹è¯æ—¥å¿—
    finish_tstamp = time.time()
    logger.info(f"{output}")

    with open(get_conv_log_filename(), "a") as fout:
        data = {
            "tstamp": round(finish_tstamp, 4),
            "type": "chat",
            "model": model_name,
            "start": round(start_tstamp, 4),
            "finish": round(finish_tstamp, 4),
            "state": state.dict(),
            "videos": all_video_hash,
            "ip": request.client.host,
        }
        fout.write(json.dumps(data) + "\n")

# å®šä¹‰äº†é¡µé¢çš„æ ‡é¢˜ï¼Œä½¿ç”¨Markdownçš„æ ‡é¢˜è¯­æ³•ï¼Œæ˜¾ç¤ºä¸ºä¸€çº§æ ‡é¢˜ã€‚
title_markdown = ("""
# HiLight: Motern Multi-modality Vision Language Model
""")

# å®šä¹‰äº†æœåŠ¡çš„ä½¿ç”¨æ¡æ¬¾ï¼Œä½¿ç”¨Markdownçš„æ ‡é¢˜å’Œåˆ—è¡¨è¯­æ³•ï¼Œæ˜¾ç¤ºä¸ºäºŒçº§æ ‡é¢˜å’Œåˆ—è¡¨é¡¹ã€‚
tos_markdown = ("""
### Terms of use
By using this service, users are required to agree to the following terms:
The service is a preview intended for motern use only. It only provides limited safety measures and may generate offensive content. It must not be used for any illegal, harmful, violent, racist, or sexual purposes. The service may collect user dialogue data for future research.
Please click the "Flag" button if you get any inappropriate answer! We will collect those to keep improving our moderator.
For an optimal experience, please use desktop computers for this demo, as mobile devices may compromise its quality.
""")

# æä¾›äº†æœ‰å…³è®¸å¯è¯ã€ä½¿ç”¨æ¡æ¬¾å’Œéšç§å®è·µçš„æ›´å¤šä¿¡æ¯ï¼Œä½¿ç”¨Markdownçš„æ ‡é¢˜å’Œé“¾æ¥è¯­æ³•ã€‚
learn_more_markdown = ("""
### License
This model is a closed-source preview version for internal personnel use only.
""")

# åŒ…å«äº†CSSæ ·å¼ï¼Œç”¨äºè®¾ç½®é¡µé¢ä¸­æŒ‰é’®çš„æœ€å°å®½åº¦
block_css = """

#buttons button {
    min-width: min(120px,100%);
}

"""

# å®šä¹‰å‡½æ•°ï¼Œç”¨äºæ„å»ºä¸€ä¸ªäº¤äº’å¼ç¤ºä¾‹åº”ç”¨
def build_demo(embed_mode, cur_dir=None, concurrency_count=10):
    # åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ¡†ç»„ä»¶ï¼Œä¸æ˜¾ç¤ºæ ‡ç­¾ï¼Œå ä½ç¬¦æ–‡æœ¬ä¸º"Enter text and press ENTER"
    textbox = gr.Textbox(show_label=False, placeholder="Enter text and press ENTER", container=False)
    # ä½¿ç”¨ Gradio.Blocks åˆ›å»ºä¸€ä¸ªåº”ç”¨ç•Œé¢ï¼Œæ ‡é¢˜ä¸º"HiLight"
    with gr.Blocks(title="HiLight", theme=gr.themes.Default(), css=block_css) as demo:
        # åˆå§‹åŒ– Gradio.State å¯¹è±¡ï¼Œç”¨äºç®¡ç†åº”ç”¨çŠ¶æ€
        state = gr.State()

        # å¦‚æœä¸æ˜¯åµŒå…¥æ¨¡å¼ï¼Œåˆ™æ˜¾ç¤ºåº”ç”¨æ ‡é¢˜çš„Markdownæ ¼å¼æ–‡æœ¬
        if not embed_mode:
            gr.Markdown(title_markdown)

        # åˆ›å»ºä¸€ä¸ªåŒ…å«å¤šä¸ªç»„ä»¶çš„è¡Œ
        with gr.Row():
            # åˆ›å»ºä¸€ä¸ªåŒ…å«å¤šä¸ªç»„ä»¶çš„åˆ—ï¼Œç¼©æ”¾æ¯”ä¾‹ä¸º3
            with gr.Column(scale=3):
                with gr.Row(elem_id="model_selector_row"):
                    # åˆ›å»ºä¸€ä¸ªä¸‹æ‹‰èœå•ç»„ä»¶ï¼Œç”¨äºé€‰æ‹©æ¨¡å‹
                    model_selector = gr.Dropdown(
                        choices=models,
                        value=models[0] if len(models) > 0 else "",
                        interactive=True,
                        show_label=False,
                        container=False)

                # åˆ›å»ºä¸€ä¸ªç”¨äºæ˜¾ç¤ºå’Œå¤„ç†å›¾åƒçš„ç»„ä»¶
                videobox = gr.Video()
                # åˆ›å»ºä¸€ä¸ªå•é€‰æŒ‰é’®ç»„ä»¶ï¼Œç”¨äºé€‰æ‹©éæ­£æ–¹å½¢å›¾åƒçš„é¢„å¤„ç†æ–¹å¼
                video_process_mode = gr.Radio(
                    ["Crop", "Resize", "Pad", "Default"],
                    value="Default",
                    label="Preprocess for non-square video", visible=False)

                # å¦‚æœå½“å‰ç›®å½•æœªæŒ‡å®šï¼Œåˆ™ä½¿ç”¨å½“å‰æ–‡ä»¶çš„ç›®å½•
                if cur_dir is None:
                    cur_dir = os.path.dirname(os.path.abspath(__file__))
                # åˆ›å»ºä¸€ä¸ªç¤ºä¾‹ç»„ä»¶ï¼Œæä¾›é¢„è®¾çš„å›¾åƒå’Œæ–‡æœ¬è¾“å…¥
                gr.Examples(examples=[
                    [f"{cur_dir}/examples/monday.jpg", "Explain why this meme is funny, and generate a picture when the weekend coming."],
                    [f"{cur_dir}/examples/woolen.png", "Show me one idea of what I could make with this?"],
                    [f"{cur_dir}/examples/extreme_ironing.jpg", "What is unusual about this video?"],
                    [f"{cur_dir}/examples/waterview.jpg", "What are the things I should be cautious about when I visit here?"],
                ], inputs=[videobox, textbox])


                with gr.Accordion("Function", open=True) as parameter_row:
                    # åˆ›å»ºä¸€ä¸ªæŠ˜å é¢æ¿ç»„ä»¶ï¼Œç”¨äºæ˜¾ç¤ºå’Œé€‰æ‹©æ˜¯å¦ä½¿ç”¨OCR
                    use_ocr = gr.Radio(choices=['Yes', 'No'], value='Yes', interactive=True, label="Use OCR")

                with gr.Accordion("Parameters", open=False) as parameter_row:
                    temperature = gr.Slider(minimum=0.0, maximum=1.0, value=0.2, step=0.1, interactive=True, label="Temperature",)
                    top_p = gr.Slider(minimum=0.0, maximum=1.0, value=0.7, step=0.1, interactive=True, label="Top P",)
                    max_output_tokens = gr.Slider(minimum=0, maximum=1024, value=512, step=64, interactive=True, label="Max output tokens",)

            # åˆ›å»ºå¦ä¸€ä¸ªåˆ—ï¼Œç¼©æ”¾æ¯”ä¾‹ä¸º7ï¼Œç”¨äºæ˜¾ç¤ºèŠå¤©æœºå™¨äººç•Œé¢
            with gr.Column(scale=7):
                chatbot = gr.Chatbot(
                    elem_id="chatbot",
                    label="HiLight Chatbot",
                    height=940,
                    layout="panel",
                )
                # åˆ›å»ºä¸€ä¸ªè¡Œï¼ŒåŒ…å«æ–‡æœ¬æ¡†å’Œæäº¤æŒ‰é’®
                with gr.Row():
                    with gr.Column(scale=7):
                        textbox.render()
                    with gr.Column(scale=1, min_width=50):
                        submit_btn = gr.Button(value="Send", variant="primary")
                # åˆ›å»ºä¸€ä¸ªè¡Œï¼ŒåŒ…å«ç‚¹èµã€ç‚¹è¸©ã€ä¸¾æŠ¥ã€é‡æ–°ç”Ÿæˆå’Œæ¸…é™¤å†å²çš„æŒ‰é’®
                with gr.Row(elem_id="buttons") as button_row:
                    upvote_btn = gr.Button(value="ğŸ‘  Upvote", interactive=False)
                    downvote_btn = gr.Button(value="ğŸ‘  Downvote", interactive=False)
                    flag_btn = gr.Button(value="âš ï¸  Flag", interactive=False)
                    #stop_btn = gr.Button(value="â¹ï¸  Stop Generation", interactive=False)
                    regenerate_btn = gr.Button(value="ğŸ”„  Regenerate", interactive=False)
                    clear_btn = gr.Button(value="ğŸ—‘ï¸  Clear", interactive=False)

        # å¦‚æœä¸æ˜¯åµŒå…¥æ¨¡å¼ï¼Œåˆ™æ˜¾ç¤ºæœåŠ¡æ¡æ¬¾å’Œäº†è§£æ›´å¤šä¿¡æ¯çš„Markdownæ ¼å¼æ–‡æœ¬
        if not embed_mode:
            gr.Markdown(function_markdown)
            gr.Markdown(tos_markdown)
            gr.Markdown(learn_more_markdown)
        # åˆ›å»ºä¸€ä¸ªä¸å¯è§çš„JSONç»„ä»¶ï¼Œç”¨äºä¼ é€’URLå‚æ•°
        url_params = gr.JSON(visible=False)

        # æ³¨å†Œäº‹ä»¶ç›‘å¬å™¨
        btn_list = [upvote_btn, downvote_btn, flag_btn, regenerate_btn, clear_btn]
        # ä¸ºç‚¹èµæŒ‰é’®æ³¨å†Œç‚¹å‡»äº‹ä»¶ï¼Œè°ƒç”¨upvote_last_responseå‡½æ•°
        upvote_btn.click(
            upvote_last_response,
            [state, model_selector],
            [textbox, upvote_btn, downvote_btn, flag_btn]
        )
        # ä¸ºç‚¹è¸©æŒ‰é’®æ³¨å†Œç‚¹å‡»äº‹ä»¶ï¼Œè°ƒç”¨downvote_last_responseå‡½æ•°
        downvote_btn.click(
            downvote_last_response,
            [state, model_selector],
            [textbox, upvote_btn, downvote_btn, flag_btn]
        )
        # ä¸ºä¸¾æŠ¥æŒ‰é’®æ³¨å†Œç‚¹å‡»äº‹ä»¶ï¼Œè°ƒç”¨flag_last_responseå‡½æ•°
        flag_btn.click(
            flag_last_response,
            [state, model_selector],
            [textbox, upvote_btn, downvote_btn, flag_btn]
        )

        # ä¸ºé‡æ–°ç”ŸæˆæŒ‰é’®æ³¨å†Œç‚¹å‡»äº‹ä»¶ï¼Œè°ƒç”¨regenerateå‡½æ•°ï¼Œç„¶åè°ƒç”¨http_botå‡½æ•°
        regenerate_btn.click(
            regenerate,
            [state, video_process_mode],
            [state, chatbot, textbox, videobox] + btn_list
        ).then(
            http_bot,
            [state, model_selector, temperature, top_p, max_output_tokens, use_ocr],
            [state, chatbot] + btn_list,
            concurrency_limit=concurrency_count
        )

        # ä¸ºæ¸…é™¤å†å²æŒ‰é’®æ³¨å†Œç‚¹å‡»äº‹ä»¶ï¼Œè°ƒç”¨clear_historyå‡½æ•°
        clear_btn.click(
            clear_history,
            None,
            [state, chatbot, textbox, videobox] + btn_list,
            queue=False
        )

        # ä¸ºæ–‡æœ¬æ¡†çš„æäº¤äº‹ä»¶æ³¨å†Œadd_textå‡½æ•°ï¼Œç„¶åè°ƒç”¨http_botå‡½æ•°
        textbox.submit(
            add_text,
            [state, textbox, videobox, video_process_mode],
            [state, chatbot, textbox, videobox] + btn_list,
            queue=False
        ).then(
            http_bot,
            [state, model_selector, temperature, top_p, max_output_tokens, use_ocr],
            [state, chatbot] + btn_list,
            concurrency_limit=concurrency_count
        )

        # ä¸ºæäº¤æŒ‰é’®æ³¨å†Œç‚¹å‡»äº‹ä»¶ï¼Œè°ƒç”¨add_textå‡½æ•°
        submit_btn.click(
            add_text,
            [state, textbox, videobox, video_process_mode],
            [state, chatbot, textbox, videobox] + btn_list
        ).then(
            http_bot,
            [state, model_selector, temperature, top_p, max_output_tokens, use_ocr],
            [state, chatbot] + btn_list,
            concurrency_limit=concurrency_count
        )

        # æ ¹æ®æ¨¡å‹åˆ—è¡¨æ¨¡å¼ï¼ŒåŠ è½½ç¤ºä¾‹æˆ–åˆ·æ–°æ¨¡å‹åˆ—è¡¨
        if args.model_list_mode == "once":
            demo.load(
                load_demo,
                [url_params],
                [state, model_selector],
                _js=get_window_url_params
            )
        elif args.model_list_mode == "reload":
            demo.load(
                load_demo_refresh_model_list,
                None,
                [state, model_selector],
                queue=False
            )
        else:
            raise ValueError(f"Unknown model list mode: {args.model_list_mode}")

    return demo


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--host", type=str, default="0.0.0.0")
    parser.add_argument("--port", type=int)
    parser.add_argument("--controller-url", type=str, default="http://localhost:21001")
    parser.add_argument("--concurrency-count", type=int, default=16)
    parser.add_argument("--model-list-mode", type=str, default="once",
        choices=["once", "reload"])
    parser.add_argument("--share", action="store_true")
    parser.add_argument("--moderate", action="store_true")
    parser.add_argument("--embed", action="store_true")
    args = parser.parse_args()
    logger.info(f"args: {args}")

    models = get_model_list()

    logger.info(args)
    # æ„å»ºGradioäº¤äº’å¼ç¤ºä¾‹åº”ç”¨ï¼Œä¼ å…¥æ˜¯å¦åµŒå…¥æ¨¡å¼å’Œå¹¶å‘è®¡æ•°å‚æ•°ã€‚
    demo = build_demo(args.embed, concurrency_count=args.concurrency_count)
    # APIå¼€æ”¾çŠ¶æ€,launchæ–¹æ³•å¯åŠ¨Gradioåº”ç”¨ï¼Œä¼ å…¥æœåŠ¡å™¨åç§°ã€ç«¯å£å·å’Œåˆ†äº«å‚æ•°ã€‚
    demo.queue(
        api_open=False
    ).launch(
        server_name=args.host,
        server_port=args.port,
        share=args.share
    )