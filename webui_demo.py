import argparse
import torch

from hilight.constants import VIDEO_TOKEN_INDEX, DEFAULT_VIDEO_TOKEN
from hilight.conversation import conv_templates, SeparatorStyle
from hilight.mm_utils import tokenizer_video_token

from typing import Dict, Optional, Sequence, List
from dataclasses import dataclass, field

import transformers
from transformers import TextStreamer
from transformers import (
    AutoTokenizer,
)
from transformers.trainer_utils import set_seed

from hilight.model.processor.hilight_video_processor import load_video
from hilight.model.language_model.hilight_gemma import HiLightGemmaForCausalLM

import gradio as gr


def disable_torch_init():
    """
    Disable the redundant torch default initialization to accelerate model creation.
    """
    setattr(torch.nn.Linear, "reset_parameters", lambda self: None)
    setattr(torch.nn.LayerNorm, "reset_parameters", lambda self: None)

def load_pretrained_model(model_args, device, model_weight):
    # å®ä¾‹åŒ–æ¨¡å‹
    model = HiLightGemmaForCausalLM.from_pretrained(
        model_weight, # work_dirs/HiLight-2B-LoRA-Merge-stage2-M101K-2epoch
        cache_dir=model_weight,
        attn_implementation=None,
        torch_dtype=(None),
    )
    # å®ä¾‹åŒ–å’ŒGemmaä¸€è‡´çš„tokenizer
    tokenizer = AutoTokenizer.from_pretrained(
        "model_zoo/LLM/gemma/tokenizer",
        cache_dir="model_zoo/LLM/gemma/tokenizer",
        model_max_length=512,
        padding_side="right",
    )
    # åˆå§‹åŒ–è§†è§‰æ¨¡å—
    model.get_model().initialize_vision_modules(
        model_args=model_args,
        fsdp=None
    )
    # è·å–åˆå§‹åŒ–åçš„è§†è§‰å¡”æ¨¡å—
    vision_tower = model.get_vision_tower()
    vision_tower_aux = model.get_vision_tower_aux()
    # æ ¹æ®è®­ç»ƒå‚æ•°å°†è§†è§‰å¡”æ¨¡å—è½¬æ¢åˆ°ç›¸åº”çš„æ•°æ®ç±»å‹å’Œè®¾å¤‡
    vision_tower.to(device)
    vision_tower_aux.to(device)

    model.eval()
    model.to(device)  # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡

    return tokenizer, model

@dataclass
class ModelArguments:
    # å®šä¹‰æ¨¡å‹ç›¸å…³çš„å‚æ•°ï¼Œå¦‚æ¨¡å‹åç§°ã€ç‰ˆæœ¬ã€æ˜¯å¦å†»ç»“éª¨å¹²ç½‘ç»œç­‰
    model_name_or_path: Optional[str] = field(default="model_zoo/LLM/gemma/gemma-2b-it")
    # æ³¨æ„HiLight-2Bä¸­configé‡Œé…ç½®çš„mm_vision_towerä¼˜å…ˆçº§æ›´é«˜
    vision_tower: Optional[str] = field(default="model_zoo/CLIP-ViP/pretrain_clipvip_base_16.pt")  # è§†è§‰å¡”ï¼ˆvision_towerï¼‰çš„åç§°æˆ–è·¯å¾„ã€‚è§†è§‰å¡”æ˜¯æ¨¡å‹ä¸­ç”¨äºå¤„ç†è§†è§‰ä¿¡æ¯çš„éƒ¨åˆ†
    vision_tower_aux: Optional[str] = field(default="model_zoo/Long-CLIP/longclip-B.pt")  # è¾…åŠ©è§†è§‰å¡”ï¼ˆauxiliary vision towerï¼‰çš„åç§°æˆ–è·¯å¾„

# é‡ç½®Gradioç•Œé¢çš„å…ƒç´ å’ŒçŠ¶æ€ã€‚
def gradio_reset(history, video_list, video_path_list, chating_videos_id, history_chat_videos_id, conv):
    if history is not None:
        history = []
    if video_list is not None:
        video_list = []
    if video_path_list is not None:
        video_path_list = []
    if chating_videos_id is not None:
        chating_videos_id = []
    if history_chat_videos_id is not None:
        history_chat_videos_id = []

    conv.messages = []
    conv.offset = 0

    # è¿”å›ä¸€ç³»åˆ—ç”¨äºæ›´æ–°Gradioç•Œé¢çš„å€¼å’Œæ§ä»¶çŠ¶æ€ã€‚
    return None, \
           conv, \
           gr.update(value=None, interactive=True, visible=True), \
           gr.update(value=None, placeholder='è¯·å…ˆä¸Šä¼ å¹¶è¯»å–è‡³å°‘ä¸€ä¸ªè§†é¢‘', interactive=False), \
           gr.update(value="è¯»å–è§†é¢‘", interactive=True), \
           history, \
           video_list, \
           video_path_list, \
           gr.update(value=None,label="å†å²å·²è¯»å–è§†é¢‘(ç‚¹å‡»ä»»æ„è§†é¢‘ä»¥ä½œä¸ºå½“å‰è§†é¢‘è¿›è¡Œé¢„è§ˆ)", visible=False), \
           chating_videos_id, \
           history_chat_videos_id

# é‡ç½®å¯¹è¯ä¿¡æ¯ï¼Œä½†ä¿ç•™æ‰€æœ‰å·²è¯»å–è§†é¢‘
def chat_reset(history, chating_videos_id, history_chat_videos_id, conv):
    print("-é‡ç½®å¯¹è¯ï¼ˆchat_resetï¼‰-")
    if history is not None:
        history = []
    if chating_videos_id is not None:
        chating_videos_id = []
    if history_chat_videos_id is not None:
        history_chat_videos_id = []

    conv.messages = []
    conv.offset = 0

    # chatbot, conv, text_input, history, chating_videos_id, history_chat_videos_id
    return None, \
           conv, \
           gr.update(value=None, interactive=True), \
           history, \
           chating_videos_id, \
           history_chat_videos_id


# è·å–videos_file(è·¯å¾„)å…¶ä¸­åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªè§†é¢‘ï¼Œå°†æ¯ä¸ªè§†é¢‘è¿›è¡Œå¤„ç†å¹¶å°†è§†é¢‘ç‰¹å¾æ·»åŠ åœ¨video_list
def load_and_process_videos(videos_file, video_list, video_path_list, device):
    # ç¡®ä¿ä¼ å…¥çš„è§†é¢‘è·¯å¾„æ˜¯å­—ç¬¦ä¸²ç±»å‹ã€‚
    assert isinstance(videos_file, str), "videos_fileè¾“å…¥å¿…é¡»ä¸ºåŒ…å«è§†é¢‘è·¯å¾„çš„å­—ç¬¦ä¸²"
    # å¦‚æœvideos_fileåŒ…å«é€—å·ï¼Œåˆ™å°†å…¶åˆ†å‰²æˆä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªè§†é¢‘æ–‡ä»¶è·¯å¾„
    if ',' in videos_file:
        videos = videos_file.split(',')
    # å¦‚æœæ²¡æœ‰é€—å·ï¼Œå°†videos_fileä½œä¸ºä¸€ä¸ªå•ç‹¬çš„å…ƒç´ æ·»åŠ åˆ°videosåˆ—è¡¨ä¸­
    else:
        videos = [videos_file]

    video_path_list.extend(videos)

    # éå†videosåˆ—è¡¨ï¼Œå¯¹æ¯ä¸ªè§†é¢‘æ–‡ä»¶åŠ è½½ï¼Œè¿”å›è§†é¢‘ç‰¹å¾æ·»åŠ åœ¨ video_list åˆ—è¡¨ä¸­
    for _video in videos:
        video = load_video(_video)
        video = video.to(device)
        video_list.append(video)  # è¿™é‡Œvideo_liståŒ…å«äº†æ‰€æœ‰videosçš„tensoräº†

    msg = "Received."  # è®¾ç½®è¿”å›æ¶ˆæ¯ä¸º"Received."
    return msg, video_list, video_path_list  # è¿”å›æ¥æ”¶æ¶ˆæ¯ä¿¡å·å’Œæ–°å¢è§†é¢‘æ•°é‡

# å¤„ç†è§†é¢‘ä¸Šä¼ é€»è¾‘ã€‚
def upload_video(video, text_input, history, video_list, video_path_list, device):
    print("--ç”¨æˆ·ç‚¹å‡»ä¸Šä¼ è§†é¢‘(upload_video)--")
    # å¦‚æœæ²¡æœ‰ä¸Šä¼ è§†é¢‘ï¼Œåˆ™è¿”å›å½“å‰ç•Œé¢çŠ¶æ€ï¼Œä¸è¿›è¡Œè§†é¢‘å¤„ç†
    if video is None:
        print("-æœªå‘ç°è§†é¢‘ï¼Œä¸è¿›è¡Œä»»ä½•å¤„ç†-")
        return gr.update(), gr.update(), gr.update(), history, video_list, video_path_list, gr.update()

    # åŠ è½½å¹¶å¤„ç†ä¸Šä¼ çš„è§†é¢‘ï¼Œè·å–å¤„ç†æ¶ˆæ¯
    llm_message, video_list, video_path_list = load_and_process_videos(video, video_list, video_path_list, device)
    print(f"-æ–°å¢è§†é¢‘å·²ç»æ·»åŠ ,video_listå½“å‰æ€»é‡ï¼š{len(video_list)},video_patch_listå½“å‰æ€»é‡ï¼š{len(video_path_list)}-")

    print("-å†å²è§†é¢‘å±•ç¤ºåŒºåŸŸå·²æ›´æ–°-")
    # è¿”å›ä¸€ç³»åˆ—ç”¨äºæ›´æ–°Gradioç•Œé¢çš„æ§ä»¶çŠ¶æ€å’Œå€¼ video, text_input, upload_button, history, video_list, video_path_list, videos_show
    return gr.update(interactive=True), \
        gr.update(placeholder='æ‚¨å¯ä»¥è¾“å…¥è‹±æ–‡,åœ¨æ–‡æœ¬ä»»æ„ä½ç½®"æ·»åŠ è§†é¢‘è‡³å¯¹è¯"å°†è§†é¢‘ä¿¡æ¯æ’å…¥æ­¤å¤„', interactive=True), \
        gr.update(value="è¯»å–è§†é¢‘", interactive=True), \
        history, \
        video_list, \
        video_path_list, \
        gr.update(value=video_path_list, visible=True)
        # gr.update(choices=video_path_list, value=video_path_list[-1] if video_path_list else None, visible=True)


# ä¸ºpromptæ·»åŠ å½“å‰è§†é¢‘çš„videoæ ‡è®°
def add_video_to_prompt(video, text_input, video_list, video_path_list, chating_videos_id, video_prefix, device):
    print("--ä¸ºæ–‡æœ¬è¾“å…¥æ¡†æ·»åŠ video_prefixæ ‡è®°(add_video_to_prompt)--")
    if video is None:  # å¦‚æœæ²¡æœ‰ä¸Šä¼ è§†é¢‘ï¼Œåˆ™ä¸åšä»»ä½•æ“ä½œ
        return gr.update(), chating_videos_id, video_list, video_path_list, gr.update()

    # å¦‚æœvideoå·²ç»ä¸Šä¼ è¿‡äº†ï¼Œåœ¨video_path_listä¸­å¯ä»¥æ‰¾åˆ°ï¼Œåˆ™æŸ¥æ‰¾å¯¹åº”ç´¢å¼•
    if video in video_path_list:
        print("-å½“å‰videoç»„ä»¶ä¸­çš„è§†é¢‘å·²ç»å­˜åœ¨äºvideo_path_listä¸­-")
        video_index = video_path_list.index(video)
    # å¦‚æœvideoè¿˜æœªä¸Šä¼ è¿‡ï¼Œæ²¡æœ‰åŒæ­¥åœ¨video_path_listä¸videos_showä¸­ï¼Œåˆ™æ‰‹åŠ¨æ‰§è¡Œä¸Šä¼ å¹¶è®°å½•ç´¢å¼•
    else:
        print("-å½“å‰videoç»„ä»¶ä¸­çš„è§†é¢‘æœªè¢«åŠ è½½è¿‡-")
        llm_message, video_list, video_path_list = load_and_process_videos(video, video_list, video_path_list, device)
        print(
            f"-æ–°å¢è§†é¢‘å·²ç»æ·»åŠ ,video_listå½“å‰æ€»é‡ï¼š{len(video_list)},video_patch_listå½“å‰æ€»é‡ï¼š{len(video_path_list)}-")
        video_index = len(video_path_list) - 1

    chating_videos_id.append(video_index)
    text_input = f"{text_input} {video_prefix} "

    # text_input, chating_videos_id, video_list, video_path_list, videos_show
    return text_input, chating_videos_id, video_list, video_path_list, gr.update(value=video_path_list, visible=True)

# å°†videos_showä¸­è¢«é€‰æ‹©çš„æ–‡ä»¶æ·»åŠ åˆ°Videoç»„ä»¶å±•ç¤º
def select_video(videos_show, evt: gr.SelectData):
    print(f"--ç›‘å¬åˆ°videos_showç»„ä»¶è¢«é€‰ä¸­--")
    selected_video_path = videos_show[evt.index]
    print(f"-videos_showè¾“å‡º{selected_video_path}-")
    return gr.update(value=selected_video_path)

# å®šä¹‰ä¸€ä¸ªå‡½æ•°gradio_askï¼Œç”¨äºå¤„ç†ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯å¹¶ç”ŸæˆèŠå¤©æœºå™¨äººçš„å›å¤ã€‚
def gradio_ask(user_message, chatbot, conv, video_prefix, chating_videos_id):
    print(f"--å¤„ç†ç”¨æˆ·è¾“å…¥(gradio_ask)--")
    # å¦‚æœç”¨æˆ·æ¶ˆæ¯ä¸ºç©ºï¼Œåˆ™è¿”å›æç¤ºä¿¡æ¯ã€‚
    if len(user_message) == 0:
        return gr.update(interactive=False, placeholder='è¾“å…¥æ–‡æœ¬ä¸åº”è¯¥ä¸ºç©ºï¼'), chatbot, conv, chating_videos_id

    # æ£€æŸ¥video_prefixå‡ºç°åœ¨user_messageä¸­çš„æ¬¡æ•°æ˜¯å¦ç­‰åŒäºchating_videos_idåˆ—è¡¨çš„é•¿åº¦
    if user_message.count(video_prefix) == len(chating_videos_id):
        chatbot = chatbot + [[user_message, None]]  # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°èŠå¤©æœºå™¨äººçš„èŠå¤©è®°å½•ä¸­ã€‚
        conv.append_message(conv.roles[0], user_message)  # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°å¯¹è¯æ¨¡æ¿ä¸­ã€‚
        conv.append_message(conv.roles[1], None)
        user_message = ""  # é‡ç½®user_message
        return user_message, chatbot, conv, chating_videos_id

    else:  # user_messageæœ‰è¯¯
        user_message = "è¾“å…¥æœ‰è¯¯ï¼Œè¯·ç¡®ä¿è§†é¢‘æ ‡è®°æ·»åŠ åä¸å†è¢«ä¿®æ”¹ï¼"
        chating_videos_id = []
        return user_message, chatbot, conv, chating_videos_id


# å®šä¹‰ä¸€ä¸ªå‡½æ•°gradio_answerï¼Œç”¨äºç”ŸæˆèŠå¤©æœºå™¨äººçš„å›ç­”ã€‚
def gradio_answer(chatbot, conv, history, tokenizer, model,
                  video_list, chating_videos_id, history_chat_videos_id, video_prefix,
                  num_beams, temperature, top_k, top_p,
                  max_new_tokens):
    print(f"--ç”ŸæˆèŠå¤©æœºå™¨äººå›ç­”(gradio_answer)--")

    # ä¸éœ€è¦è·å–å¯¹è¯å†å²ç»„æˆä¸Šä¸‹æ–‡ï¼Œget_promptè‡ªå¸¦ä¸Šä¸‹æ–‡
    # context = ""
    # # for pair in chatbot[:-1]:
    # #     context += f"user: {pair[0]}\nmodel: {pair[1]}\n"  # user/model ä¸ºgemmaæ¨¡æ¿
    # for role,message in conv.messages[:-1]:
    #     context += f"{role}: {message}\n"

    # è·å–å½“å‰å¯¹è¯çš„é—®é¢˜
    prompt = conv.get_prompt()  # ä»å¯¹è¯æ¨¡æ¿ä¸­è·å¾—æç¤ºï¼Œè€Œä¸æ˜¯chatbot[-1][0]
    system_prompt = "You need to accurately identify and understand the video I gave you and answer my questions. If the video is missing key information that you cannot answer please let me know that you cannot answer, don't lie to me.My question is:"
    prompt = f"{system_prompt}{prompt}"
    print(f"-prompt:{prompt}-")

    def tokenizer_video_token(prompt, tokenizer, video_prefix, video_token_index=VIDEO_TOKEN_INDEX, return_tensors='pt'):
        # å°†æç¤ºæŒ‰video_prefixåˆ†å‰²å¹¶åˆ†è¯
        prompt_chunks = [tokenizer(chunk).input_ids for chunk in prompt.split(video_prefix)]
        # print("prompt_chunks: ", prompt_chunks)

        # åˆå§‹åŒ–è¾“å…¥IDåˆ—è¡¨
        input_ids = []

        # å¦‚æœç¬¬ä¸€ä¸ªåˆ†è¯å—æœ‰å†…å®¹ï¼Œå¹¶ä¸”ç¬¬ä¸€ä¸ªåˆ†è¯å—çš„ç¬¬ä¸€ä¸ªtokenæ˜¯bos_token_idï¼Œåˆ™å°†å…¶æ·»åŠ åˆ° input_ids TODO:ä»€ä¹ˆæ—¶å€™éœ€è¦è‡ªåŠ¨æ·»åŠ bos_token_id???
        if len(prompt_chunks) > 0 and len(prompt_chunks[0]) > 0 and prompt_chunks[0][0] == tokenizer.bos_token_id:
            input_ids.append(prompt_chunks[0][0])
            prompt_chunks[0] = prompt_chunks[0][1:]  # ç§»é™¤å·²æ·»åŠ çš„bos_token_id
        # éå†åˆ†å‰²åçš„æ‰€æœ‰åˆ†è¯å—ï¼Œå¹¶åœ¨æ¯ä¸ªåˆ†è¯å—ä¹‹é—´æ’å…¥å›¾åƒæ ‡è®°ç´¢å¼•
        for i, chunk in enumerate(prompt_chunks):
            input_ids.extend(chunk)  # æ·»åŠ å½“å‰åˆ†è¯å—
            if i < len(prompt_chunks) - 1:
                input_ids.append(video_token_index)  # åœ¨åˆ†è¯å—ä¹‹é—´æ’å…¥å›¾åƒæ ‡è®°ç´¢å¼•
        # å¦‚æœéœ€è¦è¿”å›å¼ é‡å½¢å¼çš„ç»“æœï¼Œåˆ™è½¬æ¢ä¸ºæŒ‡å®šç±»å‹çš„å¼ é‡
        if return_tensors is not None:
            if return_tensors == 'pt':
                return torch.tensor(input_ids, dtype=torch.long)
            raise ValueError(f'Unsupported tensor type: {return_tensors}')

        # è¿”å›åˆ†è¯åçš„è¾“å…¥ID
        return input_ids

    # å°†æç¤ºè½¬æ¢ä¸ºè¾“å…¥IDï¼Œå¹¶æ·»åŠ åˆ°æ¨¡å‹ä¸­
    input_ids = tokenizer_video_token(prompt, tokenizer, video_prefix).unsqueeze(0).to(model.device)
    # print("input_ids:",input_ids)
    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)

    history_chat_videos_id.extend(chating_videos_id)
    # print(f"history_chat_videos_id:{history_chat_videos_id},chating_videos_id:{chating_videos_id}")
    if len(history_chat_videos_id) > 0 :  # å½“å­˜åœ¨è§†é¢‘ä¼ å…¥æ—¶
        print("-å­˜åœ¨è§†é¢‘è¾“å…¥-")
        # video_listä¸­å–å‡ºæœ¬è½®å¯¹è¯ä¸­æ¶‰åŠåˆ°çš„è§†é¢‘å…ƒç´ ï¼Œå †å ä¸ºå¼ é‡å¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ã€‚
        selected_video_tensors = [video_list[index] for index in history_chat_videos_id]  # æ ¹æ®ç´¢å¼•å–å‡ºå¯¹åº”çš„è§†é¢‘å¼ é‡
        video_tensor = torch.stack(selected_video_tensors).to(model.device)  # å°†è¿™äº›å¼ é‡å †å æˆä¸€ä¸ªæ‰¹æ¬¡çš„å¼ é‡
        # print("video_tensor.shape:",video_tensor.shape)
    else:  # ä¸å­˜åœ¨è§†é¢‘ä¼ å…¥æ—¶
        print("-çº¯æ–‡æœ¬è¾“å…¥-")
        video_tensor = None

    with torch.inference_mode():
        output_ids = model.generate(
            inputs=input_ids,  # æ–‡æœ¬çš„ç¼–ç å½¢å¼ï¼Œé€šå¸¸æ˜¯åˆ†è¯åçš„ç»“æœè½¬æ¢ä¸ºæ¨¡å‹èƒ½å¤Ÿç†è§£çš„IDæ ¼å¼ã€‚
            videos=video_tensor,  # è§†é¢‘tensor
            do_sample= True if temperature > 0 else False,  # æ˜¯å¦åœ¨æ–‡æœ¬ç”Ÿæˆè¿‡ç¨‹ä¸­è¿›è¡Œé‡‡æ ·
            num_beams=num_beams, # num_beams å€¼è¶Šé«˜ï¼Œç”Ÿæˆçš„åºåˆ—æ›´æœ‰å¯èƒ½æ˜¯å…¨å±€æœ€ä¼˜è§£ï¼Œä½†ä¹Ÿä¼šå¢åŠ è®¡ç®—é‡
            temperature=temperature,  # æ¸©åº¦å‚æ•°
            top_k=top_k,
            top_p=top_p,
            max_new_tokens=max_new_tokens,  # æœ€å¤§æ–°ç”Ÿæˆçš„tokenæ•°
            bos_token_id=tokenizer.bos_token_id,  # åºåˆ—å¼€å§‹çš„æ ‡è®°ID Begin of sequence token
            eos_token_id=tokenizer.eos_token_id,  # åºåˆ—ç»“æŸçš„æ ‡è®°ID End of sequence token
            pad_token_id=tokenizer.pad_token_id,  # å¡«å……æ ‡è®°ID Pad token
            streamer=streamer,  # ä¸€ä¸ªTextStreamerå¯¹è±¡ï¼Œç”¨äºæµå¼å¤„ç†ç”Ÿæˆçš„æ–‡æœ¬ï¼Œä»¥ä¾¿å®æ—¶æ˜¾ç¤ºè¾“å‡º
            use_cache=True)  # æ˜¯å¦åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ä½¿ç”¨ç¼“å­˜ï¼Œå¯ä»¥åŠ å¿«é‡å¤ç”Ÿæˆçš„é€Ÿåº¦ï¼Œä½†å¯èƒ½ä¼šå½±å“ç”Ÿæˆç»“æœçš„å¤šæ ·æ€§

    # å°†ç”Ÿæˆçš„æ–‡æœ¬IDè§£ç ä¸ºæ–‡æœ¬ï¼Œå¹¶æ›´æ–°å¯¹è¯æ¨¡æ¿
    outputs = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0].strip()
    conv.messages[-1][-1] = outputs
    # æ›´æ–°èŠå¤©æœºå™¨äººä¸­èŠå¤©è®°å½•çš„å›ç­”ã€‚
    chatbot[-1][1] = outputs
    # æ›´æ–°å†å²è®°å½•
    history.append((prompt, outputs))
    # æ¸…ç©ºchating_videos_id
    chating_videos_id = []
    # chatbot, conv, history, video_list, chating_videos_id, history_chat_videos_id
    return chatbot, conv, history, video_list, chating_videos_id, history_chat_videos_id

# è‡ªå®šä¹‰CSSæ ·å¼
custom_css = """
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans:wght@400;700&display=swap');

body {
    font-family: 'Noto Sans', sans-serif;
}

textarea, input {
    font-family: 'Noto Sans', sans-serif;
    font-size: 16px;
    color: #333333; /* æ·±ç°è‰²å­—ä½“ */
}
"""

def main():
    print('åˆå§‹åŒ–æ¨¡å‹')
    # å‚æ•°è§£æ
    parser = transformers.HfArgumentParser((ModelArguments))
    model_args, = parser.parse_args_into_dataclasses()

    disable_torch_init()  # ç¦ç”¨PyTorchçš„åˆå§‹åŒ–
    set_seed(42)

    # è®¾ç½®ç½‘é¡µçš„æ ‡é¢˜å’Œæè¿°ã€‚
    title = """<h1 align="center" style="font-size: 36px; color: #333;"> HiLight-2Bè¯•éªŒæ¼”ç¤º </h1>"""
    description = """<h3>æ­¤ç•Œé¢ä¸ºHiLightè§†è§‰è¯­è¨€æ¨¡å‹æ¼”ç¤ºï¼Œæ”¯æŒåŸºäºè§†é¢‘çš„å¤šè½®å¯¹è¯ã€‚</h3>
    <h3 style="font-size: 17px; color: #666; line-height: 1.2;">æ‚¨éœ€è¦ï¼š</h3>
    <h3 style="font-size: 16px; color: #666; line-height: 1.2;">1.é€‰æ‹©ä¸€ä¸ªæ¨¡å‹æƒé‡ã€‚</h3>
    <h3 style="font-size: 16px; color: #666; line-height: 1.2;">2.ä¸Šä¼ è§†é¢‘å¹¶ç‚¹å‡»"è¯»å–è§†é¢‘"ï¼Œç¡®ä¿æ‚¨è¯»å–è¿‡è‡³å°‘ä¸€ä¸ªè§†é¢‘ã€‚</h3>
    <h3 style="font-size: 16px; color: #666; line-height: 1.2;">3.é€‰æ‹©ä»»æ„ä¸€ä¸ªæ‚¨è¯»å–è¿‡çš„è§†é¢‘ï¼Œæ‚¨å¯ä»¥åœ¨å¯¹è¯ä¸­è¾“å…¥æ–‡æœ¬(è‹±æ–‡)çš„ä»»æ„ä½ç½®ç‚¹å‡»"æ·»åŠ è§†é¢‘åˆ°å¯¹è¯"å°†é¢„è§ˆæ¡†ä¸­çš„ç›¸åº”è§†é¢‘ä¿¡æ¯æ·»åŠ åœ¨è¾“å…¥ä¸­ã€‚è‡³æ­¤å½“æ‚¨å‘é€æ–‡æœ¬ç»™æ¨¡å‹çš„æ—¶å€™ï¼Œæ¨¡å‹å¯ä»¥æ ¹æ®æ‚¨ç»™å‡ºçš„å¯¹åº”è§†é¢‘åšå‡ºååº”ã€‚</h3>
    <h3 style="font-size: 17px; color: #666; line-height: 1.2;">æ³¨æ„äº‹é¡¹ï¼š</h3>
    <h3 style="font-size: 16px; color: #666; line-height: 1.2;">1.åœ¨ç‚¹å‡»"æ·»åŠ è§†é¢‘åˆ°å¯¹è¯"åæ–‡æœ¬æ¡†ä¸­ä¼šè‡ªåŠ¨æ·»åŠ è§†é¢‘æ ‡è®°ï¼Œæ­¤æ—¶æ‚¨ä¸èƒ½ä¿®æ”¹æˆ–ç ´åå®ƒçš„å®Œæ•´æ€§ï¼Œå¦åˆ™æ¨¡å‹å°†ä¸èƒ½è¯†åˆ«åˆ°æ‚¨åœ¨æ­¤å¤„æ’å…¥äº†è§†é¢‘ã€‚</h3>
    <h3 style="font-size: 16px; color: #666; line-height: 1.2;">2.æ‚¨ä¸èƒ½é€šè¿‡ç›´æ¥åœ¨"å†å²å·²è¯»å–è§†é¢‘"ä¸­ç›´æ¥ä¸Šä¼ æœªè¯»å–çš„è§†é¢‘ï¼Œæ‚¨éœ€è¦é€šè¿‡"ä¸Šä¼ è§†é¢‘"åŒºåŸŸå’Œ"è¯»å–è§†é¢‘"æŒ‰é’®æ¥æ­£ç¡®è°ƒç”¨æ¨¡å‹çš„è§†é¢‘åŠ è½½æ¨¡å—æå‰å°†è§†é¢‘ç¼“å­˜å¹¶è®°å½• </h3>"""

    # ä½¿ç”¨gr.Blocks()åˆ›å»ºä¸€ä¸ªGradioç•Œé¢
    with gr.Blocks(css=custom_css) as demo:
        # æ·»åŠ æ ‡é¢˜å’Œæè¿°çš„Markdownæ–‡æœ¬ã€‚
        gr.Markdown(title)
        gr.Markdown(description)

        # åˆ›å»ºä¸€ä¸ªæ°´å¹³æ’åˆ—çš„è¡Œï¼Œå…¶ä¸­åŒ…å«ä¸¤ä¸ªåˆ—ã€‚
        with gr.Row():
            # ç¬¬ä¸€ä¸ªåˆ—ï¼Œå 0.5çš„å®½åº¦æ¯”ä¾‹ã€‚
            with gr.Column(scale=0.5):  # åœ¨è¿™ä¸ªåˆ—ä¸­æ·»åŠ ä¸åŒçš„ç»„ä»¶ï¼Œå¦‚ä¸‹æ‹‰èœå•ã€å›¾åƒä¸Šä¼ ã€è§†é¢‘ä¸Šä¼ ç­‰ã€‚

                # åˆ›å»ºä¸€ä¸ªä¸‹æ‹‰èœå•ç»„ä»¶ã€‚ç”¨äºæ›´æ¢ä¸åŒæƒé‡
                model_weight = gr.Dropdown(choices=["FreezeTokenMining-M101K-2epoch", "FreezeTokenMining-VT1K-2epoch", "TuneTokenMining-M101K-3epoch", "TuneTokenMining-VT1K-2epoch"], label="é€‰æ‹©æ¨¡å‹æƒé‡", value=None)
                # åˆ›å»ºä¸€ä¸ªè§†é¢‘ä¸Šä¼ ç»„ä»¶ã€‚
                video = gr.Video(label="ä¸Šä¼ è§†é¢‘", value=None)
                # åˆ›å»ºä¸Šä¼ å’Œé‡å¯æŒ‰é’®ã€‚
                upload_button = gr.Button(value="è¯»å–è§†é¢‘", interactive=True)
                add_video2prompt = gr.Button(value="æ·»åŠ è§†é¢‘è‡³å¯¹è¯", interactive=True, variant="primary")
                chat_clear = gr.Button("é‡ç½®å¯¹è¯ ğŸ”„")
                clear = gr.Button("é‡ç½®ç•Œé¢ ğŸ”„")

                num_beams = gr.Slider(minimum=1, maximum=10, value=1, step=1, interactive=True, label="Num Beams")
                temperature = gr.Slider(minimum=0.1, maximum=2.0, value=1.0, step=0.1, interactive=True, label="Temperature")
                top_k = gr.Slider(minimum=0, maximum=5, value=1, step=1, interactive=True, label="Top_k")
                top_p = gr.Slider(minimum=0.1, maximum=1.0, value=1.0, step=0.05, interactive=True, label="Top_p")
                max_new_tokens = gr.Slider(minimum=64, maximum=2048, value=128, step=64, interactive=True, label="æœ€å¤§æ–°å¢Token")

            # ç¬¬äºŒä¸ªåˆ—ã€‚
            with gr.Column():  # åœ¨è¿™ä¸ªåˆ—ä¸­æ·»åŠ çŠ¶æ€ç»„ä»¶å’ŒèŠå¤©æœºå™¨äººç»„ä»¶ã€‚

                # è®¾å¤‡ç»„ä»¶
                device = gr.State(value=torch.device("cuda" if torch.cuda.is_available() else "cpu"))

                # èŠå¤©è®°å½•çŠ¶æ€
                history = gr.State(value=[])
                # è§†é¢‘tensoråˆ—è¡¨çŠ¶æ€ï¼Œç”¨äºåœ¨èŠå¤©è¿‡ç¨‹ä¸­ç´¯ç§¯æ‰€æœ‰ä¸Šä¼ çš„è§†é¢‘çš„ç‰¹å¾ï¼Œä»¥ä¾¿åœ¨ç”Ÿæˆæ–‡æœ¬æ—¶ä½œä¸ºè¾“å…¥æ•°æ®æä¾›ç»™æ¨¡å‹ã€‚
                video_list = gr.State(value=[])
                # è§†é¢‘è·¯å¾„åˆ—è¡¨çŠ¶æ€ï¼Œéšå¼ç”¨äºè®°å½•èŠå¤©è¿‡ç¨‹ä¸­ç´¯ç§¯æ‰€æœ‰ä¸Šä¼ çš„è§†é¢‘çš„è·¯å¾„ï¼Œåªæ˜¯ä¸ºäº†åœ¨videos_showç»„ä»¶ä¸­è¿›è¡Œå±•ç¤ºã€‚
                video_path_list = gr.State(value=[])
                # å½“å‰å¯¹è¯æ¶‰åŠåˆ°çš„è§†é¢‘ä½äºè§†é¢‘åˆ—è¡¨ä¸­çš„ç´¢å¼•
                chating_videos_id = gr.State(value=[])
                # å†å²å¯¹è¯æ¶‰åŠåˆ°çš„è§†é¢‘ä½äºè§†é¢‘åˆ—è¡¨ä¸­çš„ç´¢å¼•
                history_chat_videos_id = gr.State(value=[])
                # èŠå¤©æœºå™¨äººç»„ä»¶ã€‚
                chatbot = gr.Chatbot(label='HiLight-2Bæ¨¡å‹')
                # è®¾ç½®æ¨æ–­å¯¹è¯æ¨¡æ¿
                conv = gr.State(value=conv_templates["gemma"].copy())
                # è§†é¢‘æ ‡è®°
                video_prefix = gr.State(value="<video>")
                # ç”¨æˆ·è¾“å…¥æ–‡æœ¬æ¡†ã€‚
                text_input = gr.Textbox(placeholder='è¯·å…ˆé€‰æ‹©ä¸€ç§æ¨¡å‹æƒé‡', interactive=False)
                # with gr.Row():
                #     with gr.Column(scale=0.9):
                #         # ç”¨æˆ·è¾“å…¥æ–‡æœ¬æ¡†ã€‚
                #         text_input = gr.Textbox(placeholder='è¯·å…ˆé€‰æ‹©ä¸€ç§æ¨¡å‹æƒé‡', interactive=False)
                #     with gr.Column(scale=0.1):
                #         send_button = gr.Button(value="å‘é€", variant="primary")
                # ç”¨äºå­˜å‚¨æ¨¡å‹å’Œtokenizerçš„çŠ¶æ€
                model_state = gr.State(value=None)
                tokenizer_state = gr.State(value=None)
                # æ˜¾ç¤ºè®°å½•èŠå¤©è¿‡ç¨‹ä¸­ç´¯ç§¯æ‰€æœ‰ä¸Šä¼ çš„è§†é¢‘
                videos_show = gr.Files(value=None,label="å†å²å·²è¯»å–è§†é¢‘(ç‚¹å‡»ä»»æ„è§†é¢‘ä»¥ä½œä¸ºå½“å‰è§†é¢‘è¿›è¡Œé¢„è§ˆ)",visible=False)


        # å®šä¹‰ä¸€ä¸ªå‡½æ•° model_weightsï¼Œç”¨äºæ ¹æ®é€‰æ‹©çš„ model_weight æ›´æ–°ä¸åŒçš„æ¨¡å‹æƒé‡ã€‚
        def update_model_weights(model_weight, device):
            if isinstance(device, gr.State):
                device = device.value  # ä» gr.State è·å– torch.device ï¼Œé¿å…ç›´æ¥ä¼ å…¥gr.Srateç»„ä»¶å¼•å‘æŠ¥é”™

            # æ¸…ç†æ˜¾å­˜
            torch.cuda.empty_cache()

            if model_weight == "FreezeTokenMining-M101K-2epoch":
                tokenizer, model = load_pretrained_model(model_args, device,
                                                         "work_dir/HiLight-2B-LoRA-Merge-stage2-M101K-2epoch")
            elif model_weight == "FreezeTokenMining-VT1K-2epoch":
                tokenizer, model = load_pretrained_model(model_args, device,
                                                         "work_dir/HiLight-2B-LoRA-Merge-stage2-VT1K-2epoch")
            elif model_weight == "TuneTokenMining-M101K-3epoch":
                tokenizer, model = load_pretrained_model(model_args, device,
                                                         "work_dir/autodl-tmp/HiLight-2B-LoRA-Merge-stage2-tune(TM+LLM)M101K-3epoch")
            elif model_weight == "TuneTokenMining-VT1K-2epoch":
                tokenizer, model = load_pretrained_model(model_args, device,
                                                         "work_dir/autodl-tmp/HiLight-2B-LoRA-Merge-stage2-tune(TM+LLM)VT1K-2epoch")
            else:  # æŠ›å‡ºé”™è¯¯æœªçŸ¥æƒé‡
                raise ValueError("model_weighté€‰æ‹©äº†æœªçŸ¥æƒé‡ï¼")

            # åˆ‡æ¢æƒé‡ä¹‹åï¼Œé‡ç½®å¯¹è¯ä¿¡æ¯
            text_input = gr.update(value=None, placeholder='è¯·å…ˆä¸Šä¼ å¹¶è¯»å–è‡³å°‘ä¸€ä¸ªè§†é¢‘', interactive=True)
            chatbot = gr.update(value=None)
            chating_videos_id = gr.update(value=[])

            # è¿”å›æ›´æ–°åçš„æ¨¡å‹å’ŒtokenizerçŠ¶æ€
            return model, tokenizer, text_input, chatbot, chating_videos_id

        # ä¸ºä¸‹æ‹‰èœå•ç»„ä»¶ model_weight è®¾ç½®å˜åŒ–æ—¶çš„å›è°ƒå‡½æ•° update_model_weights, æ›´æ–°model_stateå’Œtokenizer_stateå’Œtext_inputã€‚
        model_weight.change(update_model_weights,
                            [model_weight, device],
                            [model_state, tokenizer_state, text_input, chatbot, chating_videos_id])

        # ä¸ºä¸Šä¼ æŒ‰é’® upload_button è®¾ç½®ç‚¹å‡»äº‹ä»¶ï¼Œå¯¹åº”è§†é¢‘çš„ä¸Šä¼ é€»è¾‘,åŒæ—¶éœ€è¦æ›´æ–°videos_showè§†é¢‘å±•ç¤ºåŒºåŸŸã€‚
        upload_button.click(upload_video,
                            [video, text_input, history, video_list, video_path_list, device],
                            [video, text_input, upload_button, history, video_list, video_path_list, videos_show])

        # å®šä¹‰ç‚¹å‡»æŒ‰é’®æ—¶çš„æ“ä½œ
        add_video2prompt.click(add_video_to_prompt,
                               [video, text_input, video_list, video_path_list, chating_videos_id, video_prefix, device],
                               [text_input, chating_videos_id, video_list, video_path_list, videos_show])

        # ç›‘å¬é€‰æ‹©äº‹ä»¶
        videos_show.select(select_video, videos_show, video)

        # ä¸ºæ–‡æœ¬è¾“å…¥æ¡† text_input è®¾ç½®æäº¤äº‹ä»¶ï¼Œé¦–å…ˆè°ƒç”¨ gradio_ask å‡½æ•°ï¼Œç„¶åè°ƒç”¨ gradio_answer å‡½æ•°ã€‚
        text_input.submit(
            gradio_ask,
            [text_input, chatbot, conv, video_prefix, chating_videos_id],
            [text_input, chatbot, conv, chating_videos_id]
        ).then(
            gradio_answer,
            [chatbot, conv, history, tokenizer_state, model_state,
             video_list, chating_videos_id, history_chat_videos_id, video_prefix,
             num_beams, temperature, top_k, top_p,
             max_new_tokens],
            [chatbot, conv, history, video_list, chating_videos_id, history_chat_videos_id]
        )
        # send_button.click(  # ä¸ºæ–‡æœ¬å‘é€æŒ‰é’®è®¾ç½®ç›¸åŒçš„äº‹ä»¶
        #     gradio_ask,
        #     [text_input, chatbot, video_prefix, chating_videos_id],
        #     [text_input, chatbot, chating_videos_id]
        # ).then(
        #     gradio_answer,
        #     [chatbot, history, tokenizer_state, model_state,
        #      video_list, chating_videos_id, video_prefix,
        #      num_beams, temperature, top_k, top_p,
        #      max_new_tokens],
        #     [chatbot, history, video_list, chating_videos_id]
        # )

        # ä¸ºæ¸…ç©ºæŒ‰é’® clear è®¾ç½®ç‚¹å‡»äº‹ä»¶ï¼Œè°ƒç”¨ gradio_reset å‡½æ•°é‡ç½®ç•Œé¢çŠ¶æ€ã€‚
        clear.click(gradio_reset,
                    [history, video_list, video_path_list, chating_videos_id, history_chat_videos_id, conv],
                    [chatbot, conv, video, text_input, upload_button, history, video_list, video_path_list, videos_show, chating_videos_id, history_chat_videos_id], queue=False)
        chat_clear.click(chat_reset,
                         [history, chating_videos_id, history_chat_videos_id, conv],
                         [chatbot, conv, text_input, history, chating_videos_id, history_chat_videos_id])

    # å¯åŠ¨ Gradio ç•Œé¢ï¼Œè®¾ç½® share=True å…è®¸åˆ†äº«é“¾æ¥ï¼Œinbrowser=True åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ç•Œé¢ã€‚
    demo.launch(share=True, inbrowser=True)

if __name__ == "__main__":
    main()